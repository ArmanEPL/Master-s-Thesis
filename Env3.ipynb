{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO,DQN,SAC\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from scipy.special import softmax\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.logger import configure\n",
    "import os\n",
    "#The hand of god shall strike where the faithful need help the most. \n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.logger import configure\n",
    "import os\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essential functions for the environments\n",
    "def entropy(p):\n",
    "    if p == 0 or p == 1:\n",
    "        return 0  # Standard entropy definition\n",
    "    return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n",
    "def confidence(L, vote):\n",
    "    TP, TN, FN, FP = L\n",
    "    \n",
    "    if vote == 1:\n",
    "        # Considering only positive votes\n",
    "        total_positives = TP + FP\n",
    "        if total_positives == 0:\n",
    "            return 0.0  # No positive predictions to consider\n",
    "        p_TP_given_positive = TP / total_positives\n",
    "        # Return 1 minus entropy to inverse the effect for your use case\n",
    "        return 1 - entropy(p_TP_given_positive)  # This reflects 'confidence' as per your definition\n",
    "\n",
    "    elif vote == -1:\n",
    "        # Considering only negative votes\n",
    "        total_negatives = TN + FN\n",
    "        if total_negatives == 0:\n",
    "            return 0.0  # No negative predictions to consider\n",
    "        p_TN_given_negative = TN / total_negatives\n",
    "        # Return 1 minus entropy to inverse the effect for your use case\n",
    "        return 1 - entropy(p_TN_given_negative)\n",
    "def ent(plus,negative):\n",
    "    #entropy of dataset\n",
    "    total= plus+negative\n",
    "    if total == 0.:\n",
    "        return(0)\n",
    "    p= plus/total\n",
    "    q= negative/total\n",
    "    if p == 0:\n",
    "        first =0.\n",
    "    else:\n",
    "        first= -p*np.log2(p)\n",
    "    if q==0:\n",
    "        second =0.\n",
    "    else:\n",
    "       second= - q*np.log2(q)\n",
    "    return(first+second)\n",
    "\n",
    "def split(TP,TN,FN,FP,func= ent):\n",
    "    # it considers the classifer (expert) which has performance characteristics and returns the ent of the corresponding split\n",
    "    if TP+TN+FN+FP == 0:\n",
    "        return(1.)\n",
    "    t= (TP+FP)/(TP+FP+FN+TN)\n",
    "    u= (FN+TN)/(TP+FP+FN+TN)\n",
    "    return (t* func(TP,FP)+u* func(FN,TN))\n",
    "\n",
    "def drop(TP,FP,FN,TN,func= ent, P=0.5):\n",
    "    return(func(TP+FN,FP+TN)-split(TP,TN,FN,FP,func))\n",
    "\n",
    "\n",
    "def split2(L,func = ent):\n",
    "    return(split(L[0],L[1],L[2],L[3],func=func))\n",
    "\n",
    "\n",
    "\n",
    "def drop2(L, func=ent, p=0.5):\n",
    "    #same with split L should be [TP,TN,FN,FP]\n",
    "    return(drop(L[0],L[1],L[2],L[3],func=func,P=p))\n",
    "def conf1(L,real,vote,p=0.5):\n",
    "    # L should be [TP,TN,FN,FP]\n",
    "    TP=L[0]\n",
    "    TN=L[1]\n",
    "    FN=L[2]\n",
    "    FP=L[3]\n",
    "\n",
    "    P= p\n",
    "    N= 1- P\n",
    "    match real,vote:\n",
    "        case 1,1:\n",
    "            if TP+FP==0:\n",
    "                return(P)\n",
    "            else:\n",
    "                return(TP/(TP+FP))\n",
    "        case 1,-1:\n",
    "            if TN+FN==0:\n",
    "                return(N)\n",
    "            else:\n",
    "                return(FN/(TN+FN))\n",
    "        case -1,-1:\n",
    "            if TN+FN==0:\n",
    "                return(N)\n",
    "            else:\n",
    "                return(TN/(TN+FN))\n",
    "        case -1,1:\n",
    "            if TP+FP==0:\n",
    "                return(P)\n",
    "            else:\n",
    "                return(FP/(TP+FP))\n",
    "\n",
    "def caster(L, vote, mode=None):\n",
    "    TP, TN, FN, FP = L\n",
    "    #BE VERY CAREFUL PLEASE!!!!!!!!!!  THE DEFINITIONS OF ENTROPY AND CONFUSION MATRIX HAVE BEEN REVERSED, DONE SO FOR CODE SIMPLICITY BUT MUST BE CAREFUL\n",
    "    if mode == None:\n",
    "        if vote == -1 and TN == 0 and FN == 0:\n",
    "            return -1.0  # Explicitly handle the edge case for negative vote\n",
    "        if vote == 1 and TP == 0 and FP == 0:\n",
    "            return 1.0  # Explicitly handle the edge case for positive vote\n",
    "        cast = 1 * conf1(L, 1, vote) - 1 * conf1(L, -1, vote)\n",
    "        return cast\n",
    "    \n",
    "    if mode == \"entropy\":\n",
    "        if vote == -1 and TN == 0 and FN == 0:\n",
    "            return -1.0  # Explicitly handle the edge case for negative vote\n",
    "        if vote == 1 and TP == 0 and FP == 0:\n",
    "            return 1.0  # Explicitly handle the edge case for positive vote\n",
    "        vote_multiplier = np.sign((vote + 1) * (L[0] - L[3]) / 2 + (vote - 1) * (L[1] - L[2]) / 2)\n",
    "        return vote_multiplier * confidence(L=L, vote=vote)\n",
    "    \n",
    "def guess(val,mu,var):\n",
    "    limit= val+ np.random.uniform(-(3**(1/2))*var,(3**(1/2))*var)\n",
    "    if limit>= -mu:\n",
    "        return(1.0)\n",
    "    return(-1.0)\n",
    "\n",
    "def transformer(dat,logaritmic_observation=False,n=800):\n",
    "    # data 0=number_of_times_played 1=TP, 2=FP, 3=FN, 4=TN ( modulo 5 )\n",
    "\n",
    "    #--------> NEW 1=TP, 2=TN, 3=FN, 4=FP\n",
    "    #take in data and return observation\n",
    "    #\n",
    "    this = np.array(dat, dtype=float)\n",
    "    if this[0] == 0.:\n",
    "        if logaritmic_observation == False:\n",
    "            return(np.array([0.,0.5,0.5,0.,0.]))\n",
    "        if logaritmic_observation == True:\n",
    "            return(np.array([np.log(n)+1,0.5,0.5,0.,0.]))\n",
    "    \n",
    "    ret = np.zeros_like(this)\n",
    "    ret[0] = this[0]\n",
    "    if logaritmic_observation == True:\n",
    "        ret[0] = np.log(n/this[0])\n",
    "    for i in range(4):\n",
    "        ret[i+1]=this[1+i]/this[0]\n",
    "    return(ret)\n",
    "def stochastic_round(x):\n",
    "    if x == int(x):\n",
    "        return int(x)\n",
    "    \n",
    "    lower = int(np.floor(x))\n",
    "    upper = int(np.ceil(x))\n",
    "    \n",
    "    prob_upper = x - lower\n",
    "    \n",
    "    return np.random.choice([lower, upper], p=[1 - prob_upper, prob_upper])\n",
    "\n",
    "\n",
    "class NormalizeObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Define the bounds for normalization based on the observation space of Expert1\n",
    "        self.low = self.observation_space.low\n",
    "        self.high = self.observation_space.high\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # Normalize the observation to range [0, 1]\n",
    "        normalized_obs = (observation - self.low) / (self.high - self.low)\n",
    "        return normalized_obs\n",
    "\n",
    "def linear_map(value, low, high):\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    value = np.asarray(value)\n",
    "    low = np.asarray(low)\n",
    "    high = np.asarray(high)\n",
    "    \n",
    "    # Calculate the denominator, and set it to 1 where low == high to avoid division by zero\n",
    "    denominator = np.where(low != high, high - low, 1)\n",
    "    \n",
    "    # Perform the linear mapping\n",
    "    transformed_value = 2 * (value - low) / denominator - 1\n",
    "    \n",
    "    # Set transformed values to 0 where low == high\n",
    "    transformed_value[low == high] = 0\n",
    "    \n",
    "    return np.float32(transformed_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:244: UserWarning: Your observation mat has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class Expert3(gym.Env):\n",
    "    def __init__(s, n=3,turns=8, order_type=\"no_ordering\",cost_range=[0.,0.125], perform_evaluation=True,normalized=False,logaritmic_obs= True):\n",
    "        s.n = n  # number of experts\n",
    "        s.turns = turns  # number of patients\n",
    "        s.round = 0  # the expert we choose to consult or not rn depending on ordering\n",
    "        s.t = 0  # the patient that we're treating rn\n",
    "        s.logaritmic_obs=logaritmic_obs\n",
    "        s.order_mode = order_type  # environment ordering type\n",
    "        s.perform_evaluation = perform_evaluation  # Add perform_evaluation boolean\n",
    "        s.normalized= normalized\n",
    "        s.cost_range=cost_range\n",
    "        nbr = gym.spaces.Box(low=0., high=s.turns, shape=[s.n,])  # number of visits to each expert\n",
    "        P_trust = gym.spaces.Box(low=-1., high=1., shape=(s.n,))  # how much we trust the Positive vote of an expert\n",
    "        N_trust = gym.spaces.Box(low=-1., high=1., shape=(s.n,))  # how much we trust the Negative vote of an expert\n",
    "        # The observations go [nbr of visits, P_trust, N_trust,P rate, cost, taken]\n",
    "        s.low = np.array([0, -1, -1, 0, s.cost_range[0],0])\n",
    "        s.high = np.array([s.turns-1, 1, 1, 1, s.cost_range[1],2])\n",
    "        if logaritmic_obs == True:\n",
    "            s.high= np.array([np.log(s.turns)+1, 1, 1, 1, s.cost_range[1],2])\n",
    "\n",
    "        taken = gym.spaces.MultiDiscrete(np.array([3] * s.n))\n",
    "        s.loss_for_softmax = np.array([0.] * s.n)\n",
    "        other = gym.spaces.Box(low=np.array([0., 0., 0., 0.]), high=np.array([s.turns - 1, s.turns - 1, s.n, s.n]), shape=(4,))\n",
    "        active_round = gym.spaces.MultiBinary(1)\n",
    "\n",
    "\n",
    "        #s.observation_space = gym.spaces.Dict({\"nbr\": nbr, \"P_trust\": P_trust, \"N_trust\": N_trust, \"taken\": taken, \"other\": other, \"active_round\": active_round})\n",
    "\n",
    "\n",
    "        s.low_matrix = np.tile(s.low, (s.n, 1))\n",
    "        s.high_matrix = np.tile(s.high, (s.n, 1))\n",
    "\n",
    "        s.observation_space=gym.spaces.Dict({\"mat\":gym.spaces.Box(low=s.low_matrix, high=s.high_matrix,dtype=np.float32), \"other\":gym.spaces.Box(low=0,high=s.turns-1)})\n",
    "        if normalized== True:\n",
    "            s.observation_space = spaces.Dict({\n",
    "            \"mat\": spaces.Box(low=-1*np.ones_like(s.low_matrix), high=np.ones_like(s.high_matrix), dtype=np.float32),\n",
    "            \"other\": spaces.Box(low=np.array([-1]), high=np.array([1]), dtype=np.float32)\n",
    "        })\n",
    "\n",
    "        \n",
    "\n",
    "        s.action_space = gym.spaces.MultiBinary(1)\n",
    "        s.mu_window = 1.0\n",
    "        s.var_window = 1.0\n",
    "        s.cost = 0.125\n",
    "        if s.perform_evaluation:\n",
    "            s.rewards_list = []  # Initialize the rewards list\n",
    "            s.experts_consulted = []  # Initialize the experts consulted list\n",
    "            s.correct_classifications = []  # Initialize the correct classifications list\n",
    "            s.experts_visited = []  # Initialize the experts visited list\n",
    "\n",
    "    def reset(s, seed=0):\n",
    "        s.exp_mu = np.random.uniform(-s.mu_window, s.mu_window, s.n)  # bias of experts\n",
    "        s.exp_var = np.random.uniform(0.0, s.var_window, s.n)  # variance of experts\n",
    "        s.costs= np.random.uniform(s.cost_range[0],s.cost_range[1],s.n)\n",
    "        s.l = np.random.uniform(-1.0, 1.0, s.turns)  # the patients\n",
    "        s.data = np.float32(np.array([0., 0., 0., 0., 0.] * s.n))\n",
    "        s.nbr = np.array([0.] * s.n)  # number of visits to each expert\n",
    "        s.P_trust = np.float32(np.array([0.] * s.n))  # p trust vector\n",
    "        s.N_trust = np.float32(np.array([0.] * s.n))  # n trust vector\n",
    "\n",
    "        \n",
    "        s.p_rate=np.array([0.]*s.n,dtype=np.float32)\n",
    "\n",
    "        \n",
    "        s.taken = np.array([2] * s.n, dtype=int)  # taken or not or not yet vector\n",
    "        s.other = np.float32(np.array([0, s.turns - 1, 0, s.n]))  # other relevant data\n",
    "        s.round_rews = np.zeros(s.n)  # rewards for that patient\n",
    "        s.diagnoses = np.zeros(shape=(s.n, s.turns), dtype=np.int8)  # expert*patient diagnosis matrix\n",
    "        s.ground_truth = np.zeros_like(s.l)  # patient health ground truth\n",
    "        s.final = np.zeros_like(s.l)  # final classification for patient t\n",
    "        s.res = np.zeros_like(s.l)\n",
    "        s.giver = np.float32(np.array([0.0, 0.5, 0.5, 0., 0.0] * s.n))  # for observation?\n",
    "        s.loss_for_softmax = np.array([0.] * s.n)  # loss_used only for the softmax algorithm\n",
    "        if s.perform_evaluation:\n",
    "            s.rewards_list = []  # Reset the rewards list at the beginning of an episode\n",
    "            s.experts_consulted = []  # Reset the experts consulted list at the beginning of an episode\n",
    "            s.correct_classifications = []  # Reset the correct classifications list at the beginning of an episode\n",
    "            s.experts_visited = []  # Reset the experts visited list at the beginning of an episode\n",
    "        for i in range(s.n):\n",
    "            s.nbr[i] = s.giver[5 * i]\n",
    "            s.P_trust[i] = caster(transformer(s.data[i * 5:i * 5 + 5])[1:], 1)\n",
    "            s.N_trust[i] = caster(transformer(s.data[i * 5:i * 5 + 5])[1:], -1)\n",
    "            s.p_rate=np.array(transformer(s.data[i * 5:i * 5 + 5])[1]+transformer(s.data[i * 5:i * 5 + 5])[4])\n",
    "        for i in range(s.turns):\n",
    "            s.ground_truth[i] = guess(s.l[i], 0.0, 0.0)\n",
    "            for j in range(s.n):\n",
    "                s.diagnoses[j][i] = guess(s.l[i], s.exp_mu[j], s.exp_var[j])\n",
    "        s.round = 0\n",
    "        s.t = 0\n",
    "        obs, info = s.get_obs(), s.get_info()\n",
    "        return obs, info\n",
    "\n",
    "    def step(s, action):\n",
    "        terminated, truncated = False, False\n",
    "        if s.round != s.n:  # within round expert selection\n",
    "            #s.taken[s.round] = action\n",
    "            s.taken[s.round] = action.item()\n",
    "            extra_points = (1 / s.n) * (action - 0.5) * 2 if s.ground_truth[s.t] == s.diagnoses[s.round][s.t] else -(1 / s.n) * (action - 0.5) * 2\n",
    "            s.loss_for_softmax[s.round] = 1. if s.ground_truth[s.t] == s.diagnoses[s.round][s.t] else -1.0\n",
    "            rew = [-action * s.costs[s.round] + extra_points][0]\n",
    "            #s.round_rews[s.round] = extra_points\n",
    "\n",
    "\n",
    "            s.round_rews[s.round] = extra_points.item()\n",
    "            s.round += 1\n",
    "            obs = s.get_obs()\n",
    "            info = s.get_info()  # Get info at each step\n",
    "  # Append the reward to the rewards list if perform_evaluation is True\n",
    "        else:\n",
    "            num_experts_consulted = (s.taken == 1).sum()\n",
    "            experts_visited = np.where(s.taken == 1)[0].tolist()\n",
    "            for i in range(s.n):\n",
    "                if s.taken[i] == 1:\n",
    "                    s.data[i * 5] += 1  # number of times used is stored on 0th feature of observation data modulo 5\n",
    "                    if s.diagnoses[i][s.t] == s.ground_truth[s.t]:\n",
    "                        if s.ground_truth[s.t] == 1.0:\n",
    "                            s.data[i * 5 + 1] += 1\n",
    "                        elif s.ground_truth[s.t] == -1.0:\n",
    "                            s.data[i * 5 + 2] += 1\n",
    "                    else:\n",
    "                        if s.ground_truth[s.t] == 1.0:\n",
    "                            s.data[i * 5 + 3] += 1\n",
    "                        elif s.ground_truth[s.t] == -1.0:\n",
    "                            s.data[i * 5 + 4] += 1\n",
    "            for i in range(s.n):\n",
    "                s.giver[i * 5:i * 5 + 5] = transformer(s.data[i * 5:i * 5 + 5])\n",
    "            votes = np.zeros(s.n)\n",
    "            s.loss_for_softmax = np.array([0.] * s.n)\n",
    "            for i in range(s.n):\n",
    "                votes[i] = caster(transformer(s.data[i * 5:i * 5 + 5])[1:], s.diagnoses[i][s.t])\n",
    "            votes = votes * s.taken\n",
    "            s.final[s.t] = guess(votes.mean(), 0., 0.)\n",
    "            for i in range(s.n):\n",
    "                s.nbr[i] = s.giver[5 * i]\n",
    "                s.P_trust[i] = caster(transformer(s.data[i * 5:i * 5 + 5])[1:], 1)\n",
    "                s.N_trust[i] = caster(transformer(s.data[i * 5:i * 5 + 5])[1:], -1)\n",
    "                s.p_rate=np.array(transformer(s.data[i * 5:i * 5 + 5])[1]+transformer(s.data[i * 5:i * 5 + 5])[4])\n",
    "\n",
    "            s.round = 0\n",
    "            rew = s.final[s.t] * s.ground_truth[s.t] - s.round_rews.sum() - (s.taken*s.costs).sum()\n",
    "            correct_classification = s.final[s.t] == s.ground_truth[s.t]\n",
    "\n",
    "            if s.perform_evaluation:\n",
    "                s.rewards_list.append(s.final[s.t] * s.ground_truth[s.t] - np.sum(s.costs[experts_visited]))  # Append the reward to the rewards list if perform_evaluation is True\n",
    "                s.experts_consulted.append(num_experts_consulted)  # Append the number of experts consulted\n",
    "                s.correct_classifications.append(correct_classification)  # Append the correctness of the classification\n",
    "                s.experts_visited.append(experts_visited)  # Append the list of experts visited\n",
    "            s.round_rews = np.zeros(s.n)\n",
    "            s.t += 1\n",
    "            s.taken = np.array([2] * s.n, dtype=int)\n",
    "            obs = s.get_obs()\n",
    "\n",
    "            if s.t >= s.turns:\n",
    "                truncated, terminated = True, True\n",
    "            info = s.get_info()  # Get info at the end of each patient consultation\n",
    "        #return obs, float(rew), terminated, truncated, info\n",
    "        return obs, float(rew.item()), terminated, truncated, info\n",
    "\n",
    "    def get_obs(s):\n",
    "        active_round = np.int8(np.array([1 if s.round != s.n else 0]))\n",
    "        permut = np.int8(s.get_ordering())\n",
    "        other = np.float32(np.array([s.t, s.turns - s.t - 1, s.round, s.n - s.round]))\n",
    "\n",
    "        obs1 = np.zeros_like(s.low_matrix)\n",
    "        for i in range(s.n):\n",
    "            obs1[i][0] = np.array(s.giver[5 * i])\n",
    "            if s.logaritmic_obs == True:\n",
    "                obs1[i][0] = np.array(transformer(s.data[i * 5:i * 5 + 5],n=s.turns,logaritmic_observation=s.logaritmic_obs)[0])\n",
    "            obs1[i][1] = np.array(caster(transformer(s.data[i * 5:i * 5 + 5])[1:], 1))\n",
    "            obs1[i][2] = np.array(caster(transformer(s.data[i * 5:i * 5 + 5])[1:], -1))\n",
    "            obs1[i][3] = np.array(transformer(s.data[i * 5:i * 5 + 5])[1]+transformer(s.data[i * 5:i * 5 + 5])[4])\n",
    "            obs1[i][4] = s.costs[i]\n",
    "\n",
    "            obs1[i][5] = s.taken[i]\n",
    "    \n",
    "        obs1=obs1[permut]\n",
    "        obs1= np.float32(obs1)\n",
    "        obs2= np.array([s.t],dtype=np.float32)\n",
    "\n",
    "\n",
    "        obs = {\"mat\": obs1, \"other\": obs2}\n",
    "        if s.normalized== True:\n",
    "            obs= {\"mat\": linear_map(value=obs1,low=s.low_matrix,high=s.high_matrix), \"other\": linear_map(value=obs2,low=0,high= s.turns-1)}\n",
    "            #print(obs)\n",
    "        return obs\n",
    "\n",
    "    def get_ordering(s, forced_order=None):\n",
    "        order = forced_order\n",
    "        if forced_order is None:\n",
    "            order = s.order_mode\n",
    "        unordered = np.float32(np.arange(s.n))\n",
    "        if s.round == s.n:\n",
    "            return unordered\n",
    "        match order:\n",
    "            case \"no_ordering\":\n",
    "                unordered[s.round] = -np.inf\n",
    "                permutation = np.argsort(unordered)\n",
    "                return permutation\n",
    "            case \"greedy\":\n",
    "                metric = -s.P_trust + s.N_trust\n",
    "                metric[s.round] = -np.inf\n",
    "                permutation = np.argsort(metric)\n",
    "                return permutation\n",
    "\n",
    "    def get_info(s):\n",
    "        if s.perform_evaluation:\n",
    "            return {\n",
    "                \"rewards\": s.rewards_list,\n",
    "                \"experts_consulted\": s.experts_consulted,\n",
    "                \"correct_classifications\": s.correct_classifications,\n",
    "                \"experts_visited\": s.experts_visited,\n",
    "                \"exp_mu\": s.exp_mu.tolist(),\n",
    "                \"exp_var\": s.exp_var.tolist(),\n",
    "                \"exp_costs\": s.costs.tolist()\n",
    "            }\n",
    "        return {}\n",
    "\n",
    "env3 = Expert3()\n",
    "#env4 = Expert3(order_type=\"greedy\")\n",
    "check_env(env=env3, warn=True)\n",
    "#check_env(env=env4, warn=True)\n",
    "env3.reset()\n",
    "#env4.reset()\n",
    "nenv3=Expert3( normalized=True)\n",
    "check_env(env=nenv3, warn=True)\n",
    "nenv3.reset()\n",
    "\n",
    "\n",
    "\n",
    "def play_episode(env, agent):\n",
    "    obs, info = env.reset()\n",
    "    done, truncated = False, False\n",
    "    while not (done or truncated):\n",
    "        action, _states = agent.predict(obs, deterministic=True)\n",
    "        obs, reward, truncated, done, info = env.step(action)\n",
    "    return info\n",
    "\n",
    "# Initialize environment and agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nenv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 89\u001b[0m\n\u001b[0;32m     84\u001b[0m     loaded_model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loaded_model\n\u001b[0;32m     87\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mnenv2\u001b[49m,\n\u001b[0;32m     90\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     91\u001b[0m     policy_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_extractor_class\u001b[39m\u001b[38;5;124m'\u001b[39m: CustomFeatureExtractor,\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_extractor_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m: {},\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_arch\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m24\u001b[39m]  \u001b[38;5;66;03m# Modifying the network architecture from the default [64, 64]\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     }\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Sample an observation directly from the observation space\u001b[39;00m\n\u001b[0;32m     99\u001b[0m a \u001b[38;5;241m=\u001b[39m nenv2\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39msample()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nenv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict):\n",
    "        mat_shape = observation_space.spaces['mat'].shape\n",
    "        other_shape = observation_space.spaces['other'].shape\n",
    "        mat_rows, mat_cols = mat_shape\n",
    "        num_features_per_row = 2\n",
    "        total_features_for_mat = mat_rows * num_features_per_row\n",
    "        features_dim = total_features_for_mat + other_shape[0]\n",
    "\n",
    "        super().__init__(observation_space, features_dim=features_dim)\n",
    "        self.mat_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, num_features_per_row, kernel_size=(1, mat_cols), stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        mat = observations['mat'].float().unsqueeze(1)\n",
    "        mat_features = self.mat_extractor(mat)\n",
    "        other_features = observations['other'].float()\n",
    "        combined_features = th.cat([mat_features, other_features], dim=1)\n",
    "        return combined_features\n",
    "def save_model(model, filename):\n",
    "    # Prepare hyperparameters, excluding non-serializable 'clip_range'\n",
    "    hyperparameters = {\n",
    "        'learning_rate': model.learning_rate,\n",
    "        'n_steps': model.n_steps,\n",
    "        'batch_size': model.batch_size,\n",
    "        'n_epochs': model.n_epochs,\n",
    "        'gamma': model.gamma,\n",
    "        'gae_lambda': model.gae_lambda,\n",
    "        'clip_range_vf': model.clip_range_vf,\n",
    "        'normalize_advantage': model.normalize_advantage,\n",
    "        'ent_coef': model.ent_coef,\n",
    "        'vf_coef': model.vf_coef,\n",
    "        'max_grad_norm': model.max_grad_norm,\n",
    "        'use_sde': model.use_sde,\n",
    "        'sde_sample_freq': model.sde_sample_freq,\n",
    "        'target_kl': model.target_kl,\n",
    "        'seed': model.seed\n",
    "    }\n",
    "\n",
    "    model_data = {\n",
    "        'state_dict': model.policy.state_dict(),\n",
    "        'hyperparameters': hyperparameters,\n",
    "        'policy_kwargs': model.policy_kwargs\n",
    "    }\n",
    "\n",
    "    # Save the model data to a file\n",
    "    th.save(model_data, filename)\n",
    "def load_model(filename, env, device='cpu'):\n",
    "    model_data = th.load(filename, map_location=device)\n",
    "\n",
    "    # Set a default value for clip_range if it's critical for reinitialization\n",
    "    default_clip_range = 0.2  # Default value or calculate based on other conditions\n",
    "\n",
    "    # Reinitialize the model\n",
    "    loaded_model = PPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=model_data['hyperparameters']['learning_rate'],\n",
    "        n_steps=model_data['hyperparameters']['n_steps'],\n",
    "        batch_size=model_data['hyperparameters']['batch_size'],\n",
    "        n_epochs=model_data['hyperparameters']['n_epochs'],\n",
    "        gamma=model_data['hyperparameters']['gamma'],\n",
    "        gae_lambda=model_data['hyperparameters']['gae_lambda'],\n",
    "        clip_range=default_clip_range,  # Use the default or recalculated value\n",
    "        clip_range_vf=model_data['hyperparameters']['clip_range_vf'],\n",
    "        normalize_advantage=model_data['hyperparameters']['normalize_advantage'],\n",
    "        ent_coef=model_data['hyperparameters']['ent_coef'],\n",
    "        vf_coef=model_data['hyperparameters']['vf_coef'],\n",
    "        max_grad_norm=model_data['hyperparameters']['max_grad_norm'],\n",
    "        use_sde=model_data['hyperparameters']['use_sde'],\n",
    "        sde_sample_freq=model_data['hyperparameters']['sde_sample_freq'],\n",
    "        target_kl=model_data['hyperparameters']['target_kl'],\n",
    "        policy_kwargs=model_data['policy_kwargs'],\n",
    "        seed=model_data['hyperparameters']['seed'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Load the state dictionary\n",
    "    loaded_model.policy.load_state_dict(model_data['state_dict'])\n",
    "    loaded_model.policy.eval()\n",
    "\n",
    "    return loaded_model\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    nenv3,\n",
    "    verbose=1,\n",
    "    policy_kwargs={\n",
    "        'features_extractor_class': CustomFeatureExtractor,\n",
    "        'features_extractor_kwargs': {},\n",
    "        'net_arch': [24, 24]  # Modifying the network architecture from the default [64, 64]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sample an observation directly from the observation space\n",
    "a = nenv3.observation_space.sample()\n",
    "print(\"Sampled observation:\", a)\n",
    "\n",
    "# Predict with the original model\n",
    "print(\"Using original model:\")\n",
    "original_output, _ = model.predict(a, deterministic=True)\n",
    "print(\"Output before saving:\", original_output)\n",
    "\n",
    "# Save the model\n",
    "save_model(model, 'model.pth')\n",
    "\n",
    "# Delete the model to simulate a fresh environment\n",
    "del model\n",
    "\n",
    "# Load the model\n",
    "loaded = load_model('model.pth', env=nenv3)\n",
    "\n",
    "# Predict with the loaded model\n",
    "print(\"Using loaded model:\")\n",
    "loaded_output, _ = loaded.predict(a, deterministic=True)\n",
    "print(\"Loaded Output after loading:\", loaded_output)\n",
    "\n",
    "# Compare outputs to check if they are the same\n",
    "print(\"Are outputs the same?\", th.equal(th.tensor(original_output), th.tensor(loaded_output)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
